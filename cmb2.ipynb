{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating the Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro / Goal\n",
    "\n",
    "## Setup\n",
    "\n",
    "## Device Mapping\n",
    "\n",
    "| IP                                    | Sven's Device | Maxi's Device | Fabi's Devices                         |\n",
    "| ------------------------------------- | ------------- | ------------- | -------------------------------------- |\n",
    "| 192.168.178.1                         | Router        |               |                                        |\n",
    "| 192.168.178.24                        | Google Home   |               |                                        |\n",
    "| 192.168.178.26                        | Chromecast    |               |                                        |\n",
    "| 192.168.178.27                        | Google Home   |               |                                        |\n",
    "| 192.168.178.29                        | Google Home   |               |                                        |\n",
    "| 192.168.178.42                        | Google Home   |               |                                        |\n",
    "| 192.168.178.43                        | SmartTV       |               |                                        |\n",
    "| 192.168.178.44                        | Android Phone |               |                                        |\n",
    "| 192.168.178.50                        | iPad          |               |                                        |\n",
    "| 192.168.178.51                        | MacBook       |               |                                        |\n",
    "| 192.168.178.58                        | Vacuum Robot  |               |                                        |\n",
    "| 192.168.178.60                        | MacBook       |               |                                        |\n",
    "| 192.168.178.62                        | iPhone        |               |                                        |\n",
    "| 192.168.178.64                        | SmartTV       |               |                                        |\n",
    "| 2003:c1:3720:f300:e96b:cc0b:be8f:e1e3 | GoogleHome    |               |                                        |\n",
    "| fe80::d6f5:47ff:fe38:193b             | GoogleHome    |               |                                        |\n",
    "| 2003:c1:3720:f300:99b8:9c2:5bc1:84be  | GoogleHome    |               |                                        |\n",
    "| 192.168.0.1                           |               |               | Router|\n",
    "| 192.168.0.2                           |               |               | Wifi Smart Plug                        |\n",
    "| 192.168.0.8                           |               |               | Amazon Fire TV                         |\n",
    "| 192.168.0.9                           |               |               | Sonos Wifi Loudspeaker                 |\n",
    "| 192.168.0.14                          |               |               | iPad                                   |\n",
    "| 192.168.0.22                          |               |               | ESP32 Microcontroller                  |\n",
    "| 192.168.0.88                          |               |               | Raspberry Pi used for network sniffing |\n",
    "| 192.168.0.121                         |               |               | ESP32 with Feinstaubsensor firmware    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start of the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program, run imports\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import time\n",
    "import seaborn as sns\n",
    "import requests\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "# used to skip merging and filtering\n",
    "new_read = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if new_read:\n",
    "    df_fabi = pd.read_csv(\"dumps/allPorts_fabian.csv\", encoding = \"latin\")\n",
    "    df_maxi = pd.read_csv(\"dumps/allPorts_maxi_v2.csv\", encoding = \"latin\")\n",
    "    df_sven = pd.read_csv(\"dumps/advanced-dumps-sven.csv\", encoding = \"latin\")\n",
    "    df = pd.concat([df_fabi, df_maxi, df_sven])\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter Local Traffic\n",
    "\n",
    "Print total number of captured packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if new_read:\n",
    "    # source and destination should not start with 192.168 to filter local network. DNS should not be filtered.\n",
    "    filtered = df.loc[~df['Source'].str.startswith(\"192.168\", na=False) & df['Destination'].str.startswith(\"192.168\", na=False) |\n",
    "                    df['Source'].str.startswith(\"192.168\", na=False) & ~df['Destination'].str.startswith(\"192.168\", na=False) |\n",
    "                    df['Protocol'].isin(['DNS'])]\n",
    "\n",
    "    filtered = filtered.loc[~filtered['Protocol'].isin(['DHCP', 'ARP', 'MDNS', 'LLDP', 'SSDP', 'IGMP', 'IGMPv2', 'IGMPv3', 'ICMP', 'ICMPv4', 'ICMPv6', 'ieee1905', 'LLMNR'])]\n",
    "    filtered = filtered.loc[~filtered['Destination'].isin(['255.255.255.255'])]\n",
    "\n",
    "\n",
    "    df = filtered \n",
    "\n",
    "    # sort array by timestamp\n",
    "    df = df.sort_values(by=['Time'])\n",
    "\n",
    "    # save to csv\n",
    "    df.to_csv('df.csv')\n",
    "    # print (df.loc[df['Destination'].str.contains(\"255.255.255.255\")])\n",
    "else: \n",
    "    df = pd.read_csv('df.csv')\n",
    "print(df)\n",
    "\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def utcEntryToTimestamp(entry):\n",
    "    if '.' in entry:\n",
    "        row_entry = entry.split(\".\")[0]\n",
    "    else:\n",
    "        row_entry = entry.split(\",\")[0]\n",
    "    TIME_FORMAT='%Y-%m-%d %H:%M:%S'\n",
    "    ts = int(datetime.strptime(row_entry, TIME_FORMAT).timestamp())\n",
    "    return ts\n",
    "\n",
    "def utcRowToTimestamp(row):\n",
    "    return utcEntryToTimestamp(row.at['Time'])\n",
    "utcRowToTimestamp(df.iloc[0])\n",
    "# print(df.loc[0].at['Time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protocols\n",
    "We would like to start our investigations by getting a better insight about the Packet Types were are sending to the web.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Packet Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# rank by most used protocols\n",
    "df_ranked_protocols = df.groupby('Protocol').size()\n",
    "print(df_ranked_protocols.nlargest(15))\n",
    "\n",
    "# plot pie diagram\n",
    "fig, ax = plt.subplots()\n",
    "plt.title('Protocol Distribution by Amount of Packets')\n",
    "ax.pie(df_ranked_protocols, labels=df_ranked_protocols.keys(), autopct='%1.1f%%',)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amount of Data Traffic per Protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_data_per_protocol = df.groupby('Protocol')['Length'].sum()\n",
    "print(df_data_per_protocol.nlargest(15))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.title('Protocol Distribution by Data Traffic')\n",
    "ax.pie(df_data_per_protocol, labels=df_data_per_protocol.keys(), autopct='%1.1f%%',)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Data length per Protocol Type ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_mean_protocol_packet_length = df.groupby('Protocol')['Length'].mean()\n",
    "print(df_mean_protocol_packet_length.nlargest(15))\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.tick_params(axis='x', which='major', labelsize=12)\n",
    "ax.tick_params(axis='x', which='minor', labelsize=12)\n",
    "plt.xlabel('Protocol')\n",
    "plt.ylabel('Data [Byte]')\n",
    "plt.title('Mean Data Length per Protocol Type')\n",
    "ax.bar(df_mean_protocol_packet_length.keys(), df_mean_protocol_packet_length, align='center',)\n",
    "plt.xticks(rotation=60, ha=\"right\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_ranked_sources = df.groupby('Source').size()\n",
    "print(df_ranked_sources.nlargest(25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local devices with most traffic sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[df['Source'].str.startswith(\"192.168\")].groupby('Source').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Destination Adresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_ranked_destinations = df.groupby('Destination').size()\n",
    "print(df_ranked_destinations.nlargest(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write ip address destinations to file\n",
    "unique_dests = df['Destination'].unique()\n",
    "file1 = open(\"destinations.txt\",\"w\")\n",
    "for row in unique_dests:\n",
    "    file1.write(row + \"\\n\")\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local devices with most traffic received"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[df['Destination'].str.startswith(\"192.168\")].groupby('Destination').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IP Locations World Wide Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for address, count in df_ranked_sources.nlargest(30).iteritems(): # 30 entries limit \n",
    "    if address.startswith(\"192.168.\"):\n",
    "        continue\n",
    "    headers = { 'User-Agent': \"keycdn-tools:https://www.example.com\" }\n",
    "    url = \"https://tools.keycdn.com/geo.json?host={}\".format(address)\n",
    "    json_response = requests.get(url, headers=headers).json()\n",
    "    #print(json_response)\n",
    "    geo = json_response['data']['geo']\n",
    "    #print(json_response)\n",
    "    #print(geo)\n",
    "    rows.append([geo['ip'], geo['longitude'], geo['latitude'], geo['isp']])\n",
    "    \n",
    "# as dataframe\n",
    "df_coord = pd.DataFrame(rows, columns=[\"ip\", \"lng\", \"lat\", \"isp\"])\n",
    "print(df_coord)\n",
    "df_coord.to_csv('ipLocations.csv')\n",
    "\n",
    "# plot on world\n",
    "g_world = gpd.GeoDataFrame(df_coord, geometry=gpd.points_from_xy(df_coord.lng, df_coord.lat))\n",
    "\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "base = world.plot(color='white', edgecolor='black')\n",
    "g_world.plot(ax=base, marker='o', color='red', markersize=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IP Locations World Wide Destinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for address, count in df_ranked_destinations.nlargest(30).iteritems(): # 30 entries limit \n",
    "    if address.startswith(\"192.168.\"):\n",
    "        continue\n",
    "    headers = { 'User-Agent': \"keycdn-tools:https://www.example.com\" }\n",
    "    url = \"https://tools.keycdn.com/geo.json?host={}\".format(address)\n",
    "    json_response = requests.get(url, headers=headers).json()\n",
    "    #print(json_response)\n",
    "    geo = json_response['data']['geo']\n",
    "    #print(json_response)\n",
    "    #print(geo)\n",
    "    rows.append([geo['ip'], geo['longitude'], geo['latitude'], geo['isp']])\n",
    "    \n",
    "# as dataframe\n",
    "df_coord = pd.DataFrame(rows, columns=[\"ip\", \"lng\", \"lat\", \"isp\"])\n",
    "print(df_coord)\n",
    "df_coord.to_csv('ipLocations.csv')\n",
    "\n",
    "# plot on world\n",
    "g_world = gpd.GeoDataFrame(df_coord, geometry=gpd.points_from_xy(df_coord.lng, df_coord.lat))\n",
    "\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "base = world.plot(color='white', edgecolor='black')\n",
    "g_world.plot(ax=base, marker='o', color='red', markersize=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encryption #\n",
    "\n",
    "To look at the percentage of encrypted traffic we will base our analysis solely on the used protocols. The reason behind this is that we were not able to capture the content of the traffic over time due to the memory intensity and therefore cannot look if the content is encrypted or not.\n",
    "\n",
    "To distinguish between packages with encrypt content and packages with non-encrypt content we created the following list of protocols that are used to encrypt traffic:\n",
    "- TLS\n",
    "- SSH\n",
    "- SSL\n",
    "- IPsec\n",
    "- PGP\n",
    "- S/MIME\n",
    "- UDPENCAP\n",
    "- Kerberos\n",
    "- ISAKMP\n",
    "- WireGuard\n",
    "- DTLSv1.2\n",
    "- GQUIC\n",
    "- QUIC\n",
    "- HART_IP\n",
    "- LWAPP\n",
    "\n",
    "Based on this we get the following encryption distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encrypted_protocols = ['SSH', 'SSHv2', 'SSL', 'SSLv3', 'SSLv2', 'TLS', 'TLSv1', 'TLSv1.2', 'TLSv1.3', 'IPsec', 'ESP', 'PGP', 'S/MIME', 'Kerberos', 'ISAKMP', 'UDPENCAP', 'WireGuard', 'DTLSv1.2', 'GQUIC', 'HART_IP', 'LWAPP', 'QUIC']\n",
    "encrypted_df = df.loc[df['Protocol'].isin(encrypted_protocols)]\n",
    "\n",
    "content_length_encrypted = encrypted_df['Length'].sum()\n",
    "content_length_unencrypted = df['Length'].sum()\n",
    "\n",
    "labels = 'Encrypted', 'Non-Encrypted'\n",
    "fig, ax = plt.subplots()\n",
    "plt.title('Encryption Distribution')\n",
    "ax.pie([content_length_encrypted, content_length_unencrypted - content_length_encrypted], explode=(0.1, 0), labels=labels, autopct='%1.1f%%',)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By inspecting the plot it can quickly be seen that the encrypted packages only take up a small portion of the traffic. However, this number can not be taken as an exact value but as an lower bound since packages send with the UDP and TCP protocol take up most of the traffic but could be encrypted as well. Since don't have the content of the packages we cannot further investigate into the encryption of these. But we suspect that the ecryption percentage would be a lot higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IPv6 vs IPv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ether_distribution = df.groupby('EtherType').size()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.title('EtherType Distribution')\n",
    "ax.pie(ether_distribution, labels=ether_distribution.keys(), autopct='%1.1f%%',)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNS \n",
    "\n",
    "We would like to investigate further our collected data. Now, we are particular interested in DNS requests. therefore, we filter the data by the protocol \"DNS\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_dns = df[df['Protocol'].isin(['DNS'])]\n",
    "print(df_dns.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Used DNS Server\n",
    "\n",
    "Various DNS Resolvers exist on the Internet. We would like to find out which our devices are using during their operation. \n",
    "Some devices can be configured to use specif DNS Servers, some a DNS resolver hardcoded in their firmware. In man cases the resolve request is just forwarded to the router, who takes care of this. \n",
    "By grouping our DNS Destinations and counting the requests, we see which resolvers were primarily used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dns_server = df_dns.loc[~df_dns['Info'].str.contains(\"response\")]\n",
    "print(df_dns_server.groupby(['Destination']).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that most of our DNS requests were send to our routers or well known DNS resolvers, such as Google's 8.8.8.8. However, we also found tree unknown DNS resolvers. A print out of these requests reveals that the Feinstaubsensor IoT device is talking to changing DNS Servers to resolve its destinations.\n",
    "The other one seems to be an IPv6 DNS resolver, that is used by our Amazon fire TV to resolve its requests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_dns_server.loc[df_dns_server['Destination'].str.contains(\"195.234.128.139\")].head(5))\n",
    "print(df_dns_server.loc[df_dns_server['Destination'].str.contains(\"217.68.162.126\")].head(5))\n",
    "print(df_dns_server.loc[df_dns_server['Destination'].str.contains(\"2a02:2457:10c:101::126\")].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another great insight is figuring out what URLs are actually being resolved. This can also be used to track a devices browsing behavior. We count the requests by URL to get a better overview. \\\n",
    "An interesting finding is that many of our top resolved URLs are requested by static devices, such as the Feinstaubsensor, Google Home or the Amazon Fire TV stick. \n",
    "\n",
    "Especially on personal computers and mobile devices, a brosing behavior from DNS requests can be found. This includes our love for Reddit. üë®üèΩ‚ÄçüöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only look at standart query dns requests\n",
    "df_dns_requests = df_dns[df_dns['Info'].str.contains('Standard query')]\n",
    "# exclude responses from count\n",
    "df_dns_requests = df_dns_requests[~df_dns_requests['Info'].str.contains('response')]\n",
    "# display URLS\n",
    "df_dns_urls = df_dns_requests['Info'].apply(lambda x: x.split(' ')[-1]).value_counts()\n",
    "print(df_dns_urls.head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data traffic over time ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def timeMapping(x):\n",
    "    # include time difference UTC+1\n",
    "    time = datetime.utcfromtimestamp(x*min_15_duration + 3600)\n",
    "    if time.minute == 0 and time.hour % 3 == 0:\n",
    "        return time.strftime(\"%H:%M\")\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "# find first and last timestamp, then create data structure\n",
    "min_15_duration = 60 * 15\n",
    "# df_time_mod = df.copy()\n",
    "print('Compute intensive task 1/3...')\n",
    "df['index-time'] = df['Time'] # .apply(lambda x: x)) # map to 15 min window\n",
    "df['index-time'] = df['index-time'].apply(lambda x: utcEntryToTimestamp(x))\n",
    "\n",
    "first_entry = df.iloc[0].at['index-time'] // min_15_duration\n",
    "last_entry = df.iloc[-1].at['index-time'] // min_15_duration\n",
    "\n",
    "print('from ', df.iloc[0].at['Time'], \" to \", df.iloc[-1].at['Time'])\n",
    "\n",
    "count_packets = np.zeros(last_entry - first_entry + 1)\n",
    "length_packets = np.zeros(last_entry - first_entry + 1)\n",
    "\n",
    "x_values_packets = list(range(first_entry, last_entry + 1))\n",
    "print('Amount of Intervals',len(x_values_packets))\n",
    "\n",
    "mapping_res = list(map(timeMapping, x_values_packets))\n",
    "\n",
    "print('Compute intensive task 2/3...')\n",
    "df['index-time'] = (df['index-time'] // min_15_duration) - first_entry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_packets = np.zeros(last_entry - first_entry + 1)\n",
    "length_packets = np.zeros(last_entry - first_entry + 1)\n",
    "print('Compute intensive task 3/3...')\n",
    "time_start = time.time()\n",
    "for row in df.to_dict('records'):\n",
    "    count_packets[row['index-time']] += 1\n",
    "    length_packets[row['index-time']] += row['Length']\n",
    "\n",
    "# old solution:\n",
    "#for index, row in df.iterrows():\n",
    "#    count_packets[row.at['index-time']] += 1\n",
    "#    length_packets[row.at['index-time']] += row.at['Length']\n",
    "\n",
    "time_end = time.time()\n",
    "print(time_end - time_start)\n",
    "\n",
    "length_packets = length_packets // 1000\n",
    "#print(count_packets)\n",
    "#print(length_packets)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Packets')\n",
    "plt.title('Packets per timeframe (15 min interval)')\n",
    "plt.xticks(x_values_packets, mapping_res)\n",
    "ax.bar(x_values_packets, count_packets, color='black')\n",
    "fig.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Data [kB]')\n",
    "plt.title('Data traffic per timeframe (15 min interval)')\n",
    "plt.xticks(x_values_packets, mapping_res)\n",
    "ax.bar(x_values_packets, length_packets, color='black')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of the notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

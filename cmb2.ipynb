{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction / Goal\n",
    "\n",
    "With this project we want to analyse our personal network traffic. We first want to understand general information about our network, namely the used protocols, dns servers, encryption distribution and ethertypes which are mainly used by our clients. Further, we want to analyse the sources and destinations of our requests and which devices sent the most data. Lastly, we want to inspect the collected data by searching for suspicious network traffic. To do so we want to investigate the traffic of used IoT devices and see how much / which data they share. Moreover, we will take a look at suspicious destinations to see where our data is shared to.\n",
    "\n",
    "## Setup of Hardware\n",
    "\n",
    "Our hardware setup included a Raspberry Pi which was setup as a Wifi access point and collected the network traffic using `tcpdump`. The Raspberry Pi was then connected to our local router providing access to the internet. All of us were using another access point and additional wired lan directly connected to the router. Therefore, the Raspberry Pi could not collect the whole traffic from our homes, but only a representive part of it.\n",
    "\n",
    "To collect the data we used the following tcpdump command: `tcpdump -i eth0 -G 86400  -w dumps/%Y-%m-%d_%H-%M_dump.pcap -Z root`. We captured the whole traffic which is going through the eth0 interface, so through the LAN port of the Raspberry Pi. We saved the collected dumps into daily chunks which were named after the current date. The root flag was necessary to make sure that the capturing restarted daily. \n",
    "\n",
    "## Metrics on how much data was collected\n",
    "\n",
    "How many devices , how much data\n",
    "\n",
    "## Device Mapping\n",
    "\n",
    "| IP                                    | Sven's Device | Maxi's Device | Fabi's Devices                         |\n",
    "| ------------------------------------- | ------------- | ------------- | -------------------------------------- |\n",
    "| 192.168.178.1                         | Router        |               |                                        |\n",
    "| 192.168.178.21                        |               | Android Phone |                                        |\n",
    "| 192.168.178.24                        | Google Home   |               |                                        |\n",
    "| 192.168.178.26                        | Chromecast    |               |                                        |\n",
    "| 192.168.178.27                        | Google Home   |               |                                        |\n",
    "| 192.168.178.29                        | Google Home   |               |                                        |\n",
    "| 192.168.178.42                        | Google Home   |               |                                        |\n",
    "| 192.168.178.43                        | SmartTV       |               |                                        |\n",
    "| 192.168.178.44                        | Android Phone |               |                                        |\n",
    "| 192.168.178.50                        | iPad          |               |                                        |\n",
    "| 192.168.178.51                        | MacBook       |               |                                        |\n",
    "| 192.168.178.58                        | Vacuum Robot  |               |                                        |\n",
    "| 192.168.178.59                        |               | Notebook      |                                        |\n",
    "| 192.168.178.60                        | MacBook       |               |                                        |\n",
    "| 192.168.178.62                        | iPhone        |               |                                        |\n",
    "| 192.168.178.64                        | SmartTV       |               |                                        |\n",
    "| 192.168.178.81                        | Android Phone |               |                                        |\n",
    "| 2003:c1:3712:ac00:e9ad:724d:142a:c5c9 |               | Smartphone    |                                        |\n",
    "| 2003:c1:3712:ac00:38ee:9c51:e7ee:fe52 |               | Notebook      |                                        |\n",
    "| 192.168.0.1                           |               |               | Router                                 |\n",
    "| 192.168.0.2                           |               |               | Wifi Smart Plug                        |\n",
    "| 192.168.0.8                           |               |               | Amazon Fire TV                         |\n",
    "| 192.168.0.9                           |               |               | Sonos Wifi Loudspeaker                 |\n",
    "| 192.168.0.14                          |               |               | iPad                                   |\n",
    "| 192.168.0.22                          |               |               | ESP32 Microcontroller                  |\n",
    "| 192.168.0.88                          |               |               | Raspberry Pi used for network sniffing |\n",
    "| 192.168.0.121                         |               |               | ESP32 with Feinstaubsensor firmware    |\n",
    "| fe80::271:47ff:fe8d:2e30              |               |               | Amazon Fire TV                         |\n",
    "| 2003:c1:3720:f300:44f9:8130:108c:d89  | Android Phone |               |                                        |\n",
    "| 2003:c1:3720:f300:8550:6331:20ec:7cff | Android Phone |               |                                        |\n",
    "| 2003:c1:3720:f300:35ff:69ab:67a6:7220 | Android Phone |               |                                        |\n",
    "| fe80::920c:c8ff:fed8:2441             | Chromecast    |               |                                        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# mapping for later sections\n",
    "#devices_labels = ['Router (Sven)', 'Google Home (Sven)', 'Chromecast (Sven)', 'Smart TV (Sven)', 'Android Phone (Sven)', 'iPad (Sven)', 'MacBook (Sven)', 'Vacuum Robot (Sven)', 'iPhone (Sven)',\n",
    "#                  'Android Phone (Maxi)', 'Notebook (Maxi)',]\n",
    "# no router traffic is analyzed due to potential issues caused by device <--> router communication\n",
    "# '192.168.178.1': 'Router (Sven)',\n",
    "devices_mapping = {\n",
    "                    '192.168.178.21': 'Android Phone (Maxi)',\n",
    "                    '192.168.178.24': 'Google Home (Sven)',\n",
    "                    '192.168.178.26': 'Chromecast (Sven)',\n",
    "                    '192.168.178.27': 'Google Home (Sven)',\n",
    "                    '192.168.178.29': 'Google Home (Sven)',\n",
    "                    '192.168.178.42': 'Google Home (Sven)',\n",
    "                    '192.168.178.43': 'Smart TV (Sven)',\n",
    "                    '192.168.178.44': 'Android Phone (Sven)',\n",
    "                    '192.168.178.50': 'iPad (Sven)',\n",
    "                    '192.168.178.51': 'MacBook (Sven)',\n",
    "                    '192.168.178.58': 'Vacuum Robot (Sven)',\n",
    "                    '192.168.178.59': 'Notebook (Maxi)',\n",
    "                    '192.168.178.60': 'MacBook (Sven)',\n",
    "                    '192.168.178.62': 'iPhone (Sven)',\n",
    "                    '192.168.178.64': 'Smart TV (Sven)',\n",
    "                    '192.168.178.81': 'Android Phone (Sven)',\n",
    "                    '2003:c1:3712:ac00:e9ad:724d:142a:c5c9': 'Android Phone (Maxi)',\n",
    "                    '2003:c1:3712:ac00:38ee:9c51:e7ee:fe52': 'Notebook (Maxi)',\n",
    "                    '192.168.0.2':    \"Wifi Smart Plug (Fabi)\",\n",
    "                    '192.168.0.8':    \"Amazon Fire TV (Fabi)\",\n",
    "                    '192.168.0.9':    \"Sonos Wifi Loudspeaker (Fabi)\",\n",
    "                    '192.168.0.14':   \"iPad (Fabi)\",\n",
    "                    '192.168.0.22':   \"ESP32 Microcontroller (Fabi)\",\n",
    "                    '192.168.0.88':   \"Raspberry Pi used for network sniffing (Fabi)\",\n",
    "                    '192.168.0.121':  \"ESP32 with Feinstaubsensor firmware (Fabi)\",\n",
    "                    'fe80::271:47ff:fe8d:2e30': \"Amazon Fire TV (Fabi)\",\n",
    "                    '2003:c1:3720:f300:44f9:8130:108c:d89':  \"Android Phone (Sven)\",\n",
    "                    '2003:c1:3720:f300:8550:6331:20ec:7cff':  \"Android Phone (Sven)\",\n",
    "                    '2003:c1:3720:f300:35ff:69ab:67a6:7220':  \"Android Phone (Sven)\",\n",
    "                    'fe80::920c:c8ff:fed8:2441':  \"Chromecast (Sven)\",\n",
    "\n",
    "}\n",
    "\n",
    "devices_labels = list(set(devices_mapping.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program, run imports\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import time\n",
    "import seaborn as sns\n",
    "import requests\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "# used to skip merging, filtering and intesive computation tasks\n",
    "new_read = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if new_read:\n",
    "    print('Concatenate csv files...')\n",
    "    df_fabi = pd.read_csv(\"dumps/allPorts_fabian.csv\", encoding = \"latin\")\n",
    "    df_maxi = pd.read_csv(\"dumps/allPorts_maxi_v3.csv\", encoding = \"latin\")\n",
    "    df_sven = pd.read_csv(\"dumps/advanced-dumps-sven.csv\", encoding = \"latin\")\n",
    "    df = pd.concat([df_fabi, df_maxi, df_sven])\n",
    "    print('Concatenate operation completed')\n",
    "    print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Local Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if new_read:\n",
    "    time_filter_start = time.time()\n",
    "    print('Compute intensive task filter started...')\n",
    "    # source and destination should not start with 192.168 for IPv4 addresses to filter local network. DNS should not be filtered.\n",
    "    filtered = df.loc[~df['Source'].str.startswith(\"192.168\", na=False) & df['Destination'].str.startswith(\"192.168\", na=False) |\n",
    "                    df['Source'].str.startswith(\"192.168\", na=False) & ~df['Destination'].str.startswith(\"192.168\", na=False) |\n",
    "                    df['Protocol'].isin(['DNS'])]\n",
    "\n",
    "    # Filer local IPv6 traffic\n",
    "    filtered = filtered.loc[filtered['Protocol'].isin(['DNS']) |\n",
    "                    ~(\n",
    "                        (filtered['Source'].str.startswith(\"fd00:\", na=False) | filtered['Source'].str.startswith(\"fe80:\", na=False)) &\n",
    "                        (filtered['Destination'].str.startswith(\"fd00:\", na=False) | filtered['Destination'].str.startswith(\"fe80:\", na=False))\n",
    "                    )]\n",
    "\n",
    "    filtered = filtered.loc[~filtered['Protocol'].isin(['DHCP', 'ARP', 'MDNS', 'LLDP', 'SSDP', 'IGMP', 'IGMPv2', 'IGMPv3', 'ICMP', 'ICMPv4', 'ICMPv6', 'ieee1905', 'LLMNR'])]\n",
    "    filtered = filtered.loc[~filtered['Destination'].isin(['255.255.255.255'])]\n",
    "\n",
    "\n",
    "    df = filtered \n",
    "\n",
    "    # sort array by timestamp\n",
    "\n",
    "    df = df.sort_values(by=['Time'])\n",
    "    # save to csv\n",
    "    # df.to_csv('df.csv')\n",
    "    # print (df.loc[df['Destination'].str.contains(\"255.255.255.255\")])\n",
    "    time_filter_duration = time.time() - time_filter_start\n",
    "    print('Task filter completed in ', time_filter_duration, ' seconds')\n",
    "else:\n",
    "    df = pd.read_csv('df.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Column 'Device Name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not 'Device Name' in df.columns:\n",
    "    new_read = True # save df later\n",
    "    time_device_name_calc_start = time.time()\n",
    "    print('Compute Device Name column...')\n",
    "    #df_devices = pd.DataFrame({'Source': devices_mapping.keys(), 'Device Name': devices_mapping.values()})\n",
    "    # df = df.merge(df_devices, on='Source', how='left')\n",
    "    # Apply Device Name to incoming and outgoing packets\n",
    "    df.loc[df['Source'].isin(devices_mapping.keys()), 'Device Name'] = df.loc[df['Source'].isin(devices_mapping.keys())].Source.apply(lambda x : devices_mapping[x])\n",
    "    df.loc[df['Destination'].isin(devices_mapping.keys()), 'Device Name'] = df.loc[df['Destination'].isin(devices_mapping.keys())].Destination.apply(lambda x : devices_mapping[x])\n",
    "    time_device_name_calc_duration = time.time() - time_device_name_calc_start\n",
    "    print('Compute Device Name column completed in ', time_device_name_calc_duration, ' in seconds')\n",
    "    print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate time intensive tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def utcEntryToTimestamp(entry):\n",
    "    #if '.' in entry:\n",
    "    row_entry = entry.split(\".\")[0]\n",
    "    #else:\n",
    "    #    row_entry = entry.split(\",\")[0]\n",
    "    TIME_FORMAT='%Y-%m-%d %H:%M:%S'\n",
    "    ts = int(datetime.strptime(row_entry, TIME_FORMAT).timestamp())\n",
    "    return ts\n",
    "\n",
    "def utcRowToTimestamp(row):\n",
    "    return utcEntryToTimestamp(row.at['Time'])\n",
    "utcRowToTimestamp(df.iloc[0])\n",
    "# print(df.loc[0].at['Time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "min_15_duration = 60 * 15\n",
    "# add index time column, if it doesn't exist yet\n",
    "if not 'index-time' in df.columns:\n",
    "    time_utc_calc_start = time.time()\n",
    "    print('Compute index-time column (approx. 5min)...')\n",
    "    df['index-time'] = df['Time'].apply(lambda x: utcEntryToTimestamp(x)) # .apply(lambda x: x)) # map to 15 min window\n",
    "    first_entry_offset = df.iloc[0].at['index-time'] // min_15_duration\n",
    "    df['index-time'] = (df['index-time'] // min_15_duration) - first_entry_offset\n",
    "    new_read = True\n",
    "    time_utc_calc_duration = time.time() - time_utc_calc_start\n",
    "    print('index-time column task completed in ', time_utc_calc_duration, ' seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save DF to CSV / Load DF from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if new_read:\n",
    "    df.to_csv('df.csv')\n",
    "\n",
    "print(df)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protocols\n",
    "We would like to start our investigations by getting a better insight about the Packet Types were are sending to the web.\n",
    "Several protocols exist for sending data trough the web nowadays. Based on their purpose, these cane be assigned to Application, Transport and Internet layer.\n",
    "- Application layer\n",
    "  - DNS\n",
    "  - SSH\n",
    "  - HTTP\n",
    "  - HTTPS\n",
    "  - ...\n",
    "- Transport Layer\n",
    "  - TCP\n",
    "  - UDP\n",
    "  - QUICK\n",
    "- Internet Layer\n",
    "  - IP (IPv4, IPv6)\n",
    "  - ICMP\n",
    "  - ...   \n",
    "\n",
    "Some of these protocols, such as HTTP, UDP and TCP are quite old. Others, such as the QUICK protocol, were only introduced in the recent years. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protocol Distribution Among Frames\n",
    "\n",
    "To get a better overview about all the traffic our devices use the sent and receive data from the Internet, we print out a ranking and plot the data. \\\n",
    "We see that the mayority of our captured frames use **TCP*** as underlying protocol. This is not surprising, since TCP is the most used transport protocol and is almost used for every traffic on the web. \\\n",
    "Surprisingly, we also see **QUICK** in our top 5. QUICK, which was recently standardized in May 2021, seems to be heavily pushed by its creator Google. As you can see from our device list, Google devices claim a large share out of all devices. This might be the reason for its popularity among our captured frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# rank by most used protocols\n",
    "df_ranked_protocols = df.groupby('Protocol').size()\n",
    "print(df_ranked_protocols.nlargest(15))\n",
    "\n",
    "\n",
    "# plot pie diagram\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.title('Protocol Distribution by Amount of Packets')\n",
    "ax.pie(df_ranked_protocols, labels=df_ranked_protocols.keys(), autopct='%1.1f%%')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amount of Data Traffic per Protocol\n",
    "We also had a look in the amount of data traffic that is sent by each protocol. It seemes that this heavily correlates with the protocol distribution among our captured frames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_data_per_protocol = df.groupby('Protocol')['Length'].sum()\n",
    "print(df_data_per_protocol.nlargest(15))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.title('Protocol Distribution by Data Traffic')\n",
    "ax.pie(df_data_per_protocol, labels=df_data_per_protocol.keys(), autopct='%1.1f%%',)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Data length per Protocol Type\n",
    "In order to investigate which kind if protocol holds the most data, we compute the mean of each frame per protocol.\n",
    "It seems that especially SSL and SSH have the greatest amount of data per frame. \\\n",
    "Surprisingly, we also some various industrial protocols, such as H1, PKIX-CRL and HART_IP in this ranking. These protocols are especially designed for sending large data packets. We are not very sure what programs on Maxi's laptop and phone are responsible for this and will investigate this further in a later section of this write-up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_mean_protocol_packet_length = df.groupby('Protocol')['Length'].mean()\n",
    "print(df_mean_protocol_packet_length.nlargest(15))\n",
    "#print (df.loc[df['Protocol'].str.contains(\"HART_IP\")])\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ax.tick_params(axis='x', which='major', labelsize=12)\n",
    "ax.tick_params(axis='x', which='minor', labelsize=12)\n",
    "plt.xlabel('Protocol')\n",
    "plt.ylabel('Data [Byte]')\n",
    "plt.title('Mean Data Length per Protocol Type')\n",
    "ax.bar(df_mean_protocol_packet_length.keys(), df_mean_protocol_packet_length, align='center',)\n",
    "plt.xticks(rotation=60, ha=\"right\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write ip address destinations to file\n",
    "unique_dests = df['Destination'].unique()\n",
    "file1 = open(\"destinations.txt\",\"w\")\n",
    "for row in unique_dests:\n",
    "    file1.write(row + \"\\n\")\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source and Destination Analysis\n",
    "Our devices are contacting lots of servers on the Internet. We would like to know which servers are sending and receiving the most data frames from. For this, we group our data by sources and print out the largest sources and destinations of data. Also, we filter all local sources and destinations in our home networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Sources\n",
    "df_ranked_sources = df.loc[~df['Source'].str.startswith(\"192.168\") & ~df['EtherType'].isin(['IPv6'])] \\\n",
    "    .groupby('Source').size()\n",
    "\n",
    "print('Sources of Data')\n",
    "print(df_ranked_sources.nlargest(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Destinations \n",
    "df_ranked_destinations = df.loc[~df['Destination'].str.startswith(\"192.168\") & ~df['EtherType'].isin(['IPv6'])] \\\n",
    "    .groupby('Destination').size()\n",
    "print('Destination of Data')\n",
    "print(df_ranked_destinations.nlargest(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ISPs and Location\n",
    "\n",
    "The previous print out does not reveal anything about the host and location behind the IP. Therefore, we decided to use an external API provider to reveal more data for us. The external API provider returns us a json response, were we parse the location and ISP from.\n",
    "\n",
    "Most of the source and destinations servers in our data belong to cloud providers, content delivery networks (Fastly) or video streaming services (Twitch).\n",
    "\n",
    "However, we also found also some anomalies. Among our most contacted servers is 'SWM Services GmbH', a local Munich infrastructure cooperation. We have to investigate this further in an upcoming section of this writeup. Also, there is the 'Datacamp limited'. A quick Google search reveals that this is a fraudulent isp which is used for various viruses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data about source servers\n",
    "rows = []\n",
    "for address, count in df_ranked_sources.nlargest(25).iteritems():\n",
    "    headers = { 'User-Agent': \"keycdn-tools:https://www.example.com\" }\n",
    "    url = \"https://tools.keycdn.com/geo.json?host={}\".format(address)\n",
    "    json_response = requests.get(url, headers=headers).json()\n",
    "    # print(json_response)\n",
    "    geo = json_response['data']['geo']\n",
    "    rows.append([geo['ip'], geo['country_code'], geo['longitude'], geo['latitude'], geo['isp']])\n",
    "    \n",
    "# as dataframe\n",
    "df_coord = pd.DataFrame(rows, columns=[\"ip\", \"country\", \"lng\", \"lat\", \"isp\"])\n",
    "print(df_coord)\n",
    "\n",
    "# plot on worldmap\n",
    "g_world = gpd.GeoDataFrame(df_coord, geometry=gpd.points_from_xy(df_coord.lng, df_coord.lat))\n",
    "\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "base = world.plot(color='white', edgecolor='black')\n",
    "g_world.plot(ax=base, marker='o', color='red', markersize=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IP Locations World Wide Destinations (Outgoing Traffic) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data about destination servers\n",
    "rows = []\n",
    "for address, count in df_ranked_destinations.nlargest(25).iteritems(): \n",
    "    headers = { 'User-Agent': \"keycdn-tools:https://www.example.com\" }\n",
    "    url = \"https://tools.keycdn.com/geo.json?host={}\".format(address)\n",
    "    json_response = requests.get(url, headers=headers).json()\n",
    "    #print(json_response)\n",
    "    geo = json_response['data']['geo']\n",
    "    rows.append([geo['ip'], geo['country_code'], geo['longitude'], geo['latitude'], geo['isp']])\n",
    "    \n",
    "# as dataframe\n",
    "df_coord = pd.DataFrame(rows, columns=[\"ip\", \"country\", \"lng\", \"lat\", \"isp\"])\n",
    "print(df_coord)\n",
    "\n",
    "# plot on worldmap\n",
    "g_world = gpd.GeoDataFrame(df_coord, geometry=gpd.points_from_xy(df_coord.lng, df_coord.lat))\n",
    "\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "base = world.plot(color='white', edgecolor='black')\n",
    "g_world.plot(ax=base, marker='o', color='red', markersize=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encryption\n",
    "\n",
    "To look at the percentage of encrypted traffic we will base our analysis solely on the used protocols. The reason behind this is that we were not able to capture the content of the traffic over time due to the memory intensity and therefore cannot look if the content is encrypted or not.\n",
    "\n",
    "To distinguish between packages with encrypt content and packages with non-encrypt content we will only look at the following application layer protocols and divide them between non-encrypt and encrypted:\n",
    "- Encrypted:\n",
    "  - DTLSv1.2\n",
    "  - ISAKMP\n",
    "  - RTCP\n",
    "  - SSH\n",
    "  - SSL\n",
    "  - TLS\n",
    "  - WireGuard\n",
    "\n",
    "- Non-Encrypted:\n",
    "  - DNS\n",
    "  - HTTP\n",
    "  - MP4\n",
    "  - NTP\n",
    "  - OCSP\n",
    "  - SMTP\n",
    "  \n",
    "- Uncategorized:\n",
    "  - CLASSIC-STUN\n",
    "  - HART_IP\n",
    "  - HCrt\n",
    "  - IMAP\n",
    "  - STUN\n",
    "  - XMPP\n",
    "\n",
    "Based on this we get the following encryption distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_protocols = ['ESP', 'GQUIC', 'H1', 'LWAPP', 'MPTCP', 'QUIC', 'TCP', 'THRIFT', 'TURN CHANNEL', 'UDP', 'UDPENCAP']\n",
    "encrypted_application_protocols = ['DTLSv1.2', 'ISAKMP', 'RTCP', 'SSHv2', 'SSH', 'SSL', 'SSLv2', 'SSLv3', 'TLSv1', 'TLSv1.2', 'TLSv1.3', 'WireGuard']\n",
    "non_encrypted_application_protocols = ['DNS', 'HTTP', 'HTTP/JSON', 'HTTP/JSON/XML', 'HTTP/XML', 'MP4', 'NTP', 'OCSP', 'SMTP']\n",
    "uncategorized_application_protocols = ['CLASSIC-STUN', 'HART_IP', 'HCrt', 'IMAP', 'STUN', 'XMPP/XML']\n",
    "\n",
    "only_application_protocols = df.loc[~df['Protocol'].isin(filter_protocols)]\n",
    "only_encrypted_protocols = only_application_protocols.loc[only_application_protocols['Protocol'].isin(encrypted_application_protocols)]\n",
    "only_non_encrypted_protocols = only_application_protocols.loc[only_application_protocols['Protocol'].isin(non_encrypted_application_protocols)]\n",
    "only_uncategorized_protocols = only_application_protocols.loc[only_application_protocols['Protocol'].isin(uncategorized_application_protocols)]\n",
    "\n",
    "content_length_encrypted = only_encrypted_protocols['Length'].sum()\n",
    "content_length_unencrypted = only_non_encrypted_protocols['Length'].sum()\n",
    "content_length_uncategorized = only_uncategorized_protocols['Length'].sum()\n",
    "\n",
    "labels = 'Encrypted', 'Non-Encrypted', 'Uncategorized'\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.title('Encryption Distribution')\n",
    "ax.pie([content_length_encrypted, content_length_unencrypted, content_length_uncategorized], explode=(0.1, 0, 0), labels=labels, autopct='%1.1f%%',)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By inspecting the plot it can quickly be seen that the encrypted packages only take up a small portion of the traffic. However, this number can not be taken as an exact value but as an lower bound since packages send with the UDP and TCP protocol take up most of the traffic but could be encrypted as well. Since don't have the content of the packages we cannot further investigate into the encryption of these. But we suspect that the ecryption percentage would be a lot higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IPv6 vs IPv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ether_distribution = df.groupby('EtherType').size()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.title('EtherType Distribution')\n",
    "ax.pie(ether_distribution, labels=ether_distribution.keys(), autopct='%1.1f%%',)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which devices are using IPv6?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipv6_traffic = df.loc[df['EtherType'].isin(['IPv6'])]\n",
    "\n",
    "print(ipv6_traffic.groupby(['Source']).size())\n",
    "# print(ipv6_traffic.groupby(['Source', 'Device Name']).size())\n",
    "\n",
    "# TODO find out device names for rest of IP's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNS \n",
    "\n",
    "Every device that is connected to the Internet uses DNS to resolve URLs of their desired destination services. This DNS requests are particular interesting, since they can reveal a lot of a devices web browsing behavior or the various servers it is contacting over time.\n",
    "In order to get this information, we filter our large data dump by the protocol \"DNS\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_dns = df[df['Protocol'] == 'DNS']\n",
    "print(df_dns.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Used DNS Server\n",
    "\n",
    "Various DNS resolvers exist on the Internet. We would like to find out which of these are our devices using. \n",
    "Some devices can be configured to use a specific DNS Servers, some devices have their preferred DNS resolver hardcoded in their firmware. In many cases the resolve request is just forwarded to the router, who takes care of this. \n",
    "\n",
    "By grouping our DNS Destinations and counting the requests, we see which resolvers were primarily used by our devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dns_server = df_dns.loc[~df_dns['Info'].str.contains(\"response\")]\n",
    "print(df_dns_server.groupby(['Destination']).size().nlargest(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that most of our DNS requests were send to our routers. This includes the destinations starting with *192.168.* or *fd00*. Other devices use well known DNS resolvers, such as Google's *8.8.8.8* or *2001:4860:4860::8888*. \n",
    "\n",
    "However, we also found three unknown DNS resolvers (*217.68.162.126*, *17.68.162.126* and *2a02:2457:10c:101::126*). A print out of these requests reveals that the Feinstaubsensor IoT device and the  Sonos loudspeaker are using *217.68.162.126* and *17.68.162.126* resolve their destinations. These to DNS resolvers are provided by the local ISP \"PYUR\". \\\n",
    "*2001:4860:4860::8888*  seems to be an IPv6 DNS resolver, that is used by our Amazon fire TV to resolve its requests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_dns_server.loc[df_dns_server['Destination'].str.contains(\"195.234.128.139\")].groupby('Device Name').size())\n",
    "print(df_dns_server.loc[df_dns_server['Destination'].str.contains(\"217.68.162.126\")].groupby('Device Name').size())\n",
    "print(df_dns_server.loc[df_dns_server['Destination'].str.contains(\"2a02:2457:10c:101::126\")].groupby('Device Name').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another great insight is the information about the URLs, that are actually being resolved. This can also be used to track a devices browsing behavior. We count the requests by URL to get a better overview. \\\n",
    "Many DNS requests are used internally for Fritzbox specific services (Our Router). Others, such as \"server.chillibits.com\" are contacted regulary by static IoT devices, such as the custom build air quality sensor. \\\n",
    "Especially on personal computers and mobile devices, a browsing behavior from DNS requests can be seen with this analysis. This includes our love for Reddit, as its endpoints can be seen multiple times in this DNS list. üë®üèΩ‚ÄçüöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only look at standart query dns requests\n",
    "df_dns_requests = df_dns[df_dns['Info'].str.contains('Standard query')]\n",
    "# exclude responses from count\n",
    "df_dns_requests = df_dns_requests[~df_dns_requests['Info'].str.contains('response')]\n",
    "# display URLS\n",
    "df_dns_urls = df_dns_requests['Info'].apply(lambda x: x.split(' ')[-1]).value_counts()\n",
    "print('ns-287.awsdns-35.com' in df_dns_urls.keys())\n",
    "print(df_dns_urls.nlargest(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data traffic over time ###\n",
    "\n",
    "For following sections, we form 15 minute timeframes and assign data traffic to those timeframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def timeMapping(x):\n",
    "    # apply time difference UTC+1 to labels\n",
    "    time = datetime.utcfromtimestamp((first_entry_offset+x)*min_15_duration + 3600)\n",
    "    if time.minute == 0 and time.hour == 0:\n",
    "        return time.strftime(\"%H:%M\\n%d.%m\")\n",
    "    if time.minute == 0 and time.hour % 6 == 0:\n",
    "        return time.strftime(\"%H:%M\")\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "first_entry = df.iloc[0].at['index-time']\n",
    "last_entry = df.iloc[-1].at['index-time']\n",
    "\n",
    "print('from ', df.iloc[0].at['Time'], \" to \", df.iloc[-1].at['Time'])\n",
    "\n",
    "x_values_packets = list(range(first_entry, last_entry + 1))\n",
    "print('Amount of Intervals',len(x_values_packets))\n",
    "\n",
    "mapping_res = list(map(timeMapping, x_values_packets))\n",
    "\n",
    "# flag for data traffic computation task\n",
    "values_calculated = False\n",
    "\n",
    "count_packets = np.zeros(last_entry - first_entry + 1)\n",
    "length_packets = np.zeros(last_entry - first_entry + 1)\n",
    "\n",
    "df_dict = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# calculate values for data traffic\n",
    "if not values_calculated:\n",
    "    time_start = time.time()\n",
    "    print('Compute packet count and data traffic over time 2/2...')\n",
    "    df_traffic_grouped = df.groupby(['index-time']).Length.sum()\n",
    "    df_packet_grouped = df.groupby(['index-time']).count()\n",
    "\n",
    "    for timeframe, values in df_packet_grouped.iterrows():\n",
    "        # print(ip, timeframe, values['Length'])\n",
    "        # calculate index\n",
    "        count_packets[timeframe] += values['Length']\n",
    "    # break\n",
    "    for timeframe, values in df_traffic_grouped.iteritems():\n",
    "        length_packets[timeframe] += values\n",
    "    length_packets = length_packets // 1000\n",
    "    time_end = time.time()\n",
    "    print(time_end - time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print(count_packets)\n",
    "# print(length_packets)\n",
    "fig, ax = plt.subplots(figsize=(40, 5))\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Packets')\n",
    "plt.title('Packets per timeframe (15 min interval)')\n",
    "plt.xticks(x_values_packets, mapping_res)\n",
    "ax.bar(x_values_packets, count_packets, color='black')\n",
    "fig.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(40,5))\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Data [kB]')\n",
    "plt.title('Data traffic per timeframe (15 min interval)')\n",
    "plt.xticks(x_values_packets, mapping_res)\n",
    "ax.bar(x_values_packets, length_packets, color='black')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device Evaluation ##\n",
    "\n",
    "Code for setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define data structure for device metadata\n",
    "df_device_traffic  = pd.DataFrame() # counts incoming and outgoing data\n",
    "df_device_packets = pd.DataFrame() # counts incoming and outgoing packets\n",
    "df_device_dns = pd.DataFrame() # counts dns requests per device\n",
    "\n",
    "# initialize data structure\n",
    "for name in devices_labels:\n",
    "    count_packets_device = np.zeros(2 * (last_entry - first_entry + 1)) # track incoming and outgoing traffic\n",
    "    length_packets_device = np.zeros(2 * (last_entry - first_entry + 1))\n",
    "    dns_count = np.zeros(df_dns_urls.size)\n",
    "    df_device_packets[name] = count_packets_device\n",
    "    df_device_traffic[name] = length_packets_device\n",
    "    df_device_dns[name] = dns_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Version 2\n",
    "# incoming traffic\n",
    "run_device_analysis = False\n",
    "\n",
    "if run_device_analysis:\n",
    "    print('Process incoming and outgoing traffic per device...')\n",
    "    # Outgoing traffic: Device sends traffic\n",
    "    df_device_out = df.loc[(df['Source'].isin(devices_mapping.keys()))]\n",
    "    df_device_out_packets = df_device_out.groupby(['Source', 'index-time']).count()\n",
    "    df_device_out_data = df_device_out.groupby(['Source', 'index-time']).Length.sum()\n",
    "    # Incoming traffic: Device receives packet\n",
    "    df_device_in = df.loc[(df['Destination'].isin(devices_mapping.keys()))]\n",
    "    df_device_in_packets = df_device_in.groupby(['Destination', 'index-time']).count()\n",
    "    df_device_in_data = df_device_in.groupby(['Destination', 'index-time']).Length.sum()\n",
    "\n",
    "    # filter DNS request packets, device must have send request\n",
    "    df_dns_frames = df.loc[df['Source'].isin(devices_mapping.keys()) & (df['Protocol'] == 'DNS') & (df['Info'].str.contains('Standard query'))]\n",
    "    df_dns_frames = df_dns_frames.loc[~df_dns_frames['Info'].str.contains('response')]\n",
    "    # apply map function on all frames\n",
    "    print('Compute dns request apply function...')\n",
    "    df_dns_frames['dns-request'] = df_dns_frames['Info'].apply(lambda x: x.split(\" \")[-1])\n",
    "\n",
    "    # group by device\n",
    "    df_dns_device = df_dns_frames.groupby(['Device Name', 'dns-request']).Length.count().sort_values(ascending=False)\n",
    "\n",
    "# ip address traffic destinations\n",
    "df_device_ip_dest = df.loc[(df['Source'].isin(devices_mapping.keys()))]\n",
    "df_device_ip_dest = df_device_ip_dest.groupby(['Device Name', 'Destination']).Length.count().sort_values(ascending=False)\n",
    "\n",
    "# ip address traffic sources\n",
    "df_device_ip_source = df.loc[df['Destination'].isin(devices_mapping.keys())]\n",
    "df_device_ip_source = df_device_ip_source.groupby(['Device Name', 'Source']).Length.count().sort_values(ascending=False)\n",
    "# df_device_ip_dest.head(50)\n",
    "# print(df.loc[df['Destination'].str.startswith(\"192.168\")].groupby('Destination').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# transfer processed data to data structures\n",
    "# Process Outgoing traffic\n",
    "for (ip, timeframe), values in df_device_out_packets.iterrows():\n",
    "    # print(ip, timeframe, values['Length'])\n",
    "    # calculate index\n",
    "    index = 2 * timeframe + 1\n",
    "    df_device_packets.loc[index, devices_mapping[ip]] += values['Length']\n",
    "    # break\n",
    "for (ip, timeframe), values in df_device_out_data.iteritems():\n",
    "    index = 2 * timeframe + 1\n",
    "    df_device_traffic.loc[index, devices_mapping[ip]] += values\n",
    "\n",
    "# Process Incoming traffic\n",
    "for (ip, timeframe), values in df_device_in_packets.iterrows():\n",
    "    # print(ip, timeframe, values['Length'])\n",
    "    # calculate index\n",
    "    index = 2 * timeframe\n",
    "    df_device_packets.loc[index, devices_mapping[ip]] += values['Length']\n",
    "    # break\n",
    "for (ip, timeframe), values in df_device_in_data.iteritems():\n",
    "    index = 2 * timeframe\n",
    "    df_device_traffic.loc[index, devices_mapping[ip]] += values\n",
    "\n",
    "# Process DNS requests\n",
    "dns_keys = list(df_dns_urls.keys())\n",
    "for (label, address), values in df_dns_device.iteritems():\n",
    "    index = dns_keys.index(address)\n",
    "    df_device_dns.loc[index, label] += values\n",
    "# print(df_dns_frames, type(df_dns_frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# save to csv\n",
    "df_dns_urls.to_csv('df_dns_urls.csv')\n",
    "df_device_traffic.to_csv('df_device_traffic.csv')\n",
    "df_device_packets.to_csv('df_device_packets.csv')\n",
    "df_device_dns.to_csv('df_device_dns.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device Communication Endpoints ###\n",
    "\n",
    "#### Outgoing Traffic (Upload) ####\n",
    "The first place on amount of outgoing packets to the same location goes to the ESP32 and the MVG endpoint ('188.164.238.26') which receives one request per second.\n",
    "Maxi's notebook also had many outgoing packets, many popular destinations ('52.223.201.182', '52.223.201.100' and '185.42.205.193') lead us to a host such as 'video-edge-c68130.fra02.no-abs.hls.ttvnw.net' and belongs to the livestreaming service Twitch. Some Oracle cloud addresses can be traced back to Zoom (e.g. zoomff130-61-166-170mmr.cloud.zoom.us for 130.61.166.170) and there is also captured outgoing to an video streaming service CDN from Limelight Networks ('178.79.232.14').\n",
    "\n",
    "In the notebook traffic, there is also university related traffic such as '138.246.224.36' for an university IDP project. '131.159.0.186' refers to a 'rbgse35.in.tum.de' hostname, which is responsible for BBB-traffic. Other university related addresses are '129.187.255.213' (the sync and share platform from the LRZ) and '141.40.250.3' (some LRZ address).\n",
    "Other popular destinations are mostly related to Zoom, Spotify, Amazon and Twitch.\n",
    "\n",
    "With '89.187.169.39' and '185.59.220.199', Sven's smartphone has some suspicious activities that are further analyzed in the extra topic section.\n",
    "\n",
    "#### Incoming Traffic (Download) ####\n",
    "The device with the highest download traffic was Maxi's notebook which was used for watching Twitch livestreams ('52.223.201.182' and '52.223.201.100'), communicating with Microsoft ('52.113.63.202') and communicating with a Zoom service hosted in the Oracle cloud ('130.61.166.170'). \n",
    "Sven's notebook also used Zoom, but the server was different ('134.224.101.38').\n",
    "\n",
    "Maxi's smartphone often communicated with Reddit, therefore the connection with Fastly's CDN ('199.232.189.140') is no real surprise. Fabian's speaker was also often connected to Fastly CDN, one explanation would content streaming from Spotify ('199.232.138.248'). Sven's Macbook was often involved in Zoom calls ('134.224.101.38'). We observed some traffic from Sven's Chromecast to an Amazon server ('54.182.252.136') which were related to his Amazon Prime video subscription. \n",
    "A little surprising was the favourite source address '52.113.47.239' from Sven's iPhone, it is a Microsoft server and not from Apple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_device_ip_dest.head(25) # output outgoing traffic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_device_ip_source.head(25) # output popular incoming traffic ip addresses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traffic by Device ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By far, the most traffic was produced by Maxi's notebook due to high media consumption in the form of videos and watching livestreams. Furthermore, the device also has a high upload traffic caused by this project and sharing preprocessed data to other group members. \n",
    "\n",
    "Other devices with much download traffic were smartphones, Macbook, Chromecast and one ESP32 device for the MVG departures. Interestingly, although the amount of web requests and web responses is almost equal, the responses are much larger. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for each device, plot a bar that shows the data traffic (incoming and outgoing) and amount of packets\n",
    "# aggregate data\n",
    "df_device_in_total = (df_device_traffic.iloc[::2].agg(['sum']) // 1000).transpose()# even rows, incoming traffic\n",
    "df_device_out_total = (df_device_traffic.iloc[1::2].agg(['sum']) //1000).transpose()# odd rows, outgoing traffic\n",
    "\n",
    "df_device_in_total_num = df_device_in_total['sum'].to_numpy()\n",
    "df_device_out_total_num = df_device_out_total['sum'].to_numpy()\n",
    "\n",
    "df_device_in_packets_total = (df_device_packets.iloc[::2].agg(['sum'])).transpose()# even rows, incoming traffic\n",
    "df_device_out_packets_total = (df_device_packets.iloc[1::2].agg(['sum'])).transpose()# odd rows, outgoing traffic\n",
    "df_device_in_packets_total_num = df_device_in_packets_total['sum'].to_numpy()\n",
    "df_device_out_packets_total_num = df_device_out_packets_total['sum'].to_numpy()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "plt.xlabel('Devices')\n",
    "plt.ylabel('Data [kB]')\n",
    "plt.title('Data traffic per Device')\n",
    "plot_x_devices_traffic = np.arange(len(devices_labels))\n",
    "plt.xticks(plot_x_devices_traffic, devices_labels, rotation=60, ha=\"right\")\n",
    "ax.bar(plot_x_devices_traffic, df_device_in_total_num, width=0.4, label=\"Download\", color='green')\n",
    "ax.bar(plot_x_devices_traffic + 0.4, df_device_out_total_num, width=0.4, label=\"Upload\", color='red')\n",
    "ax.legend()\n",
    "fig.show()\n",
    "\n",
    "# plot packets\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "plt.xlabel('Devices')\n",
    "plt.ylabel('Packets')\n",
    "plt.title('Packets per Device')\n",
    "plot_x_devices_traffic = np.arange(len(devices_labels))\n",
    "plt.xticks(plot_x_devices_traffic, devices_labels, rotation=60, ha=\"right\")\n",
    "ax.bar(plot_x_devices_traffic, df_device_in_packets_total_num, width=0.4, label=\"Download\", color='green')\n",
    "ax.bar(plot_x_devices_traffic + 0.4, df_device_out_packets_total_num, width=0.4, label=\"Upload\", color='red')\n",
    "ax.legend()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device Activity ###\n",
    "\n",
    "The following plot shows at which timeframes packets from or to the device were captured. A single captured packet in a timeframe is sufficient to identify the device as \"active\". It does not show user activity, but it visualizes when the device was connected to the network and if it was used for data exchange with the web.\n",
    "\n",
    "For Fabian's measurements, the capture stopped approximately 12 hours than the others and therefore are incomplete for the related devices. Another issue was the connection behaviour of some devices, which connected to a neighbouring Wifi network and the Raspberry Pi could not capture the traffic in certain timeframes (e.g. applicable to iPads and some smartphones).\n",
    "\n",
    "The first group of devices were always online, some devices send data even during standby phases. Examples are the Fire TV stick, ESP32 device with Feinstaubsensor firmware, the SONOS speaker or the ESP32 with MVG requests. The ESP32 devices were configured by the user to always send requests to endpoints, the more suspicious devices are the speaker and the TV stick with web requests in short intervals. The wifi smart plug was also regularly online, but the intervals between web requests were larger than 15 minutes.\n",
    "\n",
    "The second group of devices were only sending data while they were switched on, smartphones, notebooks or the Smart TV belong to this group. In the diagrams below, the intervals with an active connection to the Raspberry Pi can be clearly identified. In some cases (e.g. Maxi's smartphone), the device had a permanent connection during the night and still communicated to the Internet although the user was sleeping.\n",
    "\n",
    "One interesting devices is the vacuum cleaner, which often was active for around 24 hours per session and effectively only worked for a few hours. The Google Home device was also connected for a longer amount of time until it randomly decided to disconnect from the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plot activity\n",
    "# activity = 1 packet send/received within a timeframe\n",
    "packets_1 = df_device_packets.iloc[::2].to_numpy()\n",
    "packets_2 = df_device_packets.iloc[1::2].to_numpy()\n",
    "\n",
    "combined = np.minimum(np.add(packets_1, packets_2), 1).transpose()\n",
    "# print(df_device_packets.iloc[::2])\n",
    "print(combined.shape)\n",
    "plot_X_activity = np.arange(combined.shape[1])\n",
    "\n",
    "\n",
    "# df_device_packets.iloc[1::2]\n",
    "fig, ax = plt.subplots(nrows=combined.shape[0], ncols=1, figsize=[20, 40])\n",
    "plt.setp(ax, xticks=x_values_packets, xticklabels=mapping_res,\n",
    "        yticks=[0, 1],xlabel='Time', ylabel=\"Activity\", )\n",
    "\n",
    "for index in range(combined.shape[0]):\n",
    "    # plt.subplot(combined.shape[0], 1, index+1)\n",
    "    if index % 2 == 0:\n",
    "        ax[index].plot(x_values_packets, combined[index], label=devices_labels[index], color=\"red\")\n",
    "    else:\n",
    "        ax[index].plot(x_values_packets, combined[index], label=devices_labels[index], color=\"blue\")\n",
    "    ax[index].legend()\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Night Behaviour and Application Behavior ###\n",
    "- Analyze night behaviour (0-6 am) (low activity, find destination IP addresses, country, isp, protocols)\n",
    "- Application Activity (e.g. Google, Twitch, MVG, etc.)\n",
    "\n",
    "We wanted to know how devices behaved at night without user interaction. Therefore, we decided to only use captured data between 10pm and 6am for the first section.\n",
    "In the second section, we want to find out more about application behavior, e.g. when any Google application is active. Therefore, we assign to each larger application a set of ip addresses (e.g. via resolving collected dns requests) and plot the activity of the applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isNighttime(timeframe):\n",
    "    timestamp = (first_entry_offset + timeframe) * min_15_duration\n",
    "    hour = datetime.fromtimestamp(timestamp).hour\n",
    "    #if hour >= 21 or hour < 8: \n",
    "    #    print(datetime.fromtimestamp(timestamp), hour <= 5 or hour >= 22)\n",
    "    return hour <= 5 or hour >= 22\n",
    "\n",
    "#for i in x_values_packets:\n",
    "isNighttime = list(map(isNighttime, x_values_packets))\n",
    "fig, ax = plt.subplots(figsize=(40,5))\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Data [kB]')\n",
    "plt.title('Data traffic per timeframe (15 min interval)')\n",
    "plt.xticks(x_values_packets, mapping_res)\n",
    "ax.plot(x_values_packets, isNighttime, color='black')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraud source\n",
    "print(df.loc[(df['Source'].isin(['89.187.169.15']))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the Mule\n",
    "\n",
    "During our network traffic analysis we came along some suspicious outliers. This included\n",
    "- SWM Services GmbH being in our top contacted server\n",
    "- An ISP called \"Datacamp Limited\", which was the top contact of an android phone\n",
    "- several Industrial protocols that are used to sent large packets of data to the web\n",
    "- lots of traffic traffic from an Xiaomi \"Smart Vaccuum Robot\"\n",
    "\n",
    "In this section we will investigate these phenomena closer and try to understand what is happening here in our networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forgotten Subway Depature Display\n",
    "We've found our first suspicious case during our source and Destination analyis. Here, we got a server belonging to \"SWM Services GmbH\". Let's see what is going on here and why it is in our top contacted servers of all our devices. \n",
    "\n",
    "First, we need to know which of our devices is contacting this server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swm = df.loc[df['Destination'].isin(['188.164.238.26'])] \n",
    "print(swm.groupby(['Device Name']).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only device that is contacting SWM is our ESP32 Microcontroller. This Microcontroller is used to display live subway departure times on a small display. Hence, it makes sense that it would regulary contact SWM Services GmbH to get the data from their server.\n",
    "\n",
    "However, there seems to be something misconfigured with the number of requests. Printing out the timestamps of each sent and received data frame shows us that we have around 25 packets within 10 seconds sent from and to SWM. During our 5 day data capture, this summed up to a total of 1057066 packages of data. \n",
    "\n",
    "This device is running 24/7 for several years now. We quite sure now that SWM did not implement a rate limit on their public Api endpoint. Else, this horrendous Api spamming would've not been possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(swm.Time.head(25))\n",
    "print(\"Number of total packages: {}\".format(len(swm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## myLoc managed IT AG\n",
    "Anime Seite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suspicious H1 protocol sends large amount of data to cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roborock Vacuum Robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacuum_traffic = df.loc[df['Device Name'].isin(['Vacuum Robot (Sven)'])].groupby('Destination').size()\n",
    "print(vacuum_traffic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data about destination servers\n",
    "rows = []\n",
    "for address, count in vacuum_traffic.iteritems(): \n",
    "    if address.startswith('192.168'):\n",
    "        continue\n",
    "    headers = { 'User-Agent': \"keycdn-tools:https://www.example.com\" }\n",
    "    url = \"https://tools.keycdn.com/geo.json?host={}\".format(address)\n",
    "    json_response = requests.get(url, headers=headers).json()\n",
    "    geo = json_response['data']['geo']\n",
    "    rows.append([geo['ip'], geo['country_code'], geo['longitude'], geo['latitude'], geo['isp']])\n",
    "\n",
    "# as dataframe\n",
    "df_coord = pd.DataFrame(rows, columns=[\"ip\", \"country\", \"lng\", \"lat\", \"isp\"])\n",
    "print(df_coord)\n",
    "\n",
    "# plot on worldmap\n",
    "g_world = gpd.GeoDataFrame(df_coord, geometry=gpd.points_from_xy(df_coord.lng, df_coord.lat))\n",
    "\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "base = world.plot(color='white', edgecolor='black')\n",
    "g_world.plot(ax=base, marker='o', color='red', markersize=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mitmproxy analysis\n",
    "\n",
    "\n",
    "GET https://api-eu.roborock.com/user/homes/712040/rooms\n",
    "\n",
    "[{\"id\":4015991,\"name\":\"Bedroom 2\"},{\"id\":768374,\"name\":\"Office\"},{\"id\":768370,\"name\":\"Bathroom\"},{\"id\":768366,\"name\":\"Bedroom\"},{\"id\":768364,\"name\":\"Floor 2\"},{\"id\":768360,\"name\":\"Living Room\"},{\"id\":768356,\"name\":\"Floor\"},{\"id\":768352,\"name\":\"Kitchen\"}]\n",
    "\n",
    "We couldn't identify any security issues with the Roborock API. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datacamp Limited\n",
    "\n",
    "https://scamalytics.com/ip/isp/datacamp-limited\n",
    "\n",
    "https://www.dnb.com/business-directory/company-profiles.datacamp_limited.914baba433b38b62196ceb3cc013b06f.html\n",
    "\n",
    "two employees generating 50 mio usd.\n",
    "hmmm.\n",
    "\n",
    "MangaMelon is behind the dns requests to the datacamp servers\n",
    "\n",
    "connections to bunny.net -> deliverying mangas\n",
    "\n",
    "founder has 100 mio euro \n",
    "https://translate.google.com/website?tl=de&client=webapp&u=https://cs.m.wikipedia.org/wiki/Zden%25C4%259Bk_Cendra&sl=cs\n",
    "\n",
    "traffic all encrypted with tls\n",
    "\n",
    "TODO plot how often requests are made\n",
    "\n",
    "app is aus dem playstore geflogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacamp_traffic = df.loc[df['Destination'].isin(['89.187.169.15', '89.187.169.39', '185.59.220.199', '185.59.220.198', '185.59.220.194', '185.59.220.193'])].groupby('Device Name').size()\n",
    "print(datacamp_traffic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This are our final thoughts before dying due to Covid-19"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
